# Flujos de EjecuciÃ³n de Test Agent

> **VersiÃ³n:** 0.7.0 â€” Arquitectura LLM-First con Tool Calling  
> **Fecha:** Febrero 2026

> **âš ï¸ NOTA SOBRE LLM:** Todas las llamadas a LLM son **reales**. La extensiÃ³n usa la API `vscode.lm` para comunicarse con modelos (GPT-4, GPT-4o, etc.) a travÃ©s de GitHub Copilot. Las respuestas se procesan en streaming. Los costos y rate limits aplican segÃºn la suscripciÃ³n de Copilot del usuario.

---

## Ãndice
1. [Arquitectura General](#arquitectura-general)
2. [ActivaciÃ³n de la ExtensiÃ³n](#activaciÃ³n-de-la-extensiÃ³n)
3. [Sistema de Tools](#sistema-de-tools)
4. [LLMOrchestrator â€” Loop AgÃ©ntico](#llmorchestrator--loop-agÃ©ntico)
5. [Flujo del Chat Handler Principal](#flujo-del-chat-handler-principal)
6. [Comando /setup](#comando-setup)
7. [Comando /install](#comando-install)
8. [Comando /generate](#comando-generate)
9. [Comando /generate-all](#comando-generate-all)
10. [DetecciÃ³n Inteligente de Dependencias (3 capas)](#detecciÃ³n-inteligente-de-dependencias-3-capas)
11. [Servicios Auxiliares](#servicios-auxiliares)
12. [Llamadas Reales al LLM](#llamadas-reales-al-llm)

---

## Arquitectura General

```
Usuario â”€â”€â–º @test-agent /comando
                â”‚
                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ extension.ts (punto de entrada)          â”‚
â”‚   â€¢ Inicializa LLMProvider               â”‚
â”‚   â€¢ Crea ToolRegistry (8 tools)          â”‚
â”‚   â€¢ Crea LLMOrchestrator                 â”‚
â”‚   â€¢ Registra chat participant            â”‚
â”‚   â€¢ Registra comandos VS Code            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ChatHandlers.ts (enrutador de comandos)  â”‚
â”‚   â€¢ handleSetupRequest()                 â”‚
â”‚   â€¢ handleInstallRequest()               â”‚
â”‚   â€¢ handleGenerateSingleRequest()        â”‚
â”‚   â€¢ handleGenerateAllRequest()           â”‚
â”‚   â€¢ handleError()                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ LLMOrchestrator (loop agÃ©ntico)          â”‚
â”‚   â€¢ execute()           â†’ libre          â”‚
â”‚   â€¢ executeGenerateAndHeal() â†’ dirigido  â”‚
â”‚                                          â”‚
â”‚   LLM decide quÃ© tools llamar           â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚   â”‚ ToolRegistry (8 tools)         â”‚     â”‚
â”‚   â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚     â”‚
â”‚   â”‚ â”‚Deterministasâ”‚ â”‚Inteligentesâ”‚  â”‚     â”‚
â”‚   â”‚ â”‚ 6 tools    â”‚ â”‚ 2 tools    â”‚  â”‚     â”‚
â”‚   â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚     â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ActivaciÃ³n de la ExtensiÃ³n

**Archivo:** `extension.ts`  
**FunciÃ³n:** `activate(context: vscode.ExtensionContext)`

```
CUANDO extensiÃ³n se activa:
    1. INSTANCIAR singleton Logger
    2. CREAR StateService(context)
    3. OBTENER configuraciÃ³n desde ConfigService
    4. CONFIGURAR nivel de log

    5. SELECCIONAR proveedor LLM:
       SI config tiene azureOpenAI.endpoint + apiKey + deploymentName:
           provider = new AzureOpenAIProvider()
       SINO:
           provider = new CopilotProvider(vendor, family)

    6. CREAR sistema de tools:
       toolRegistry = OrchestratorFactory.createToolRegistry(provider)
         â†’ Registra 6 tools deterministas + 2 inteligentes
       orchestrator = new LLMOrchestrator(toolRegistry, provider)

    7. REGISTRAR participant de chat:
       - ID: 'test-agent'
       - Handler: handleChatRequest
       - Icono: icon.png

    8. REGISTRAR comandos VS Code:
       - 'test-agent.setup'              â†’ handleSetupCommand()
       - 'test-agent.checkSetup'         â†’ handleCheckSetupCommand()
       - 'test-agent.installWithCommand'  â†’ abre chat con /install

    9. OBSERVAR cambios de configuraciÃ³n:
       ConfigService.onDidChangeConfiguration â†’ actualizar logLevel
```

---

## Sistema de Tools

### BaseTool (clase abstracta)

Todos los tools heredan de `BaseTool` y definen:

```typescript
abstract get name(): string;           // Nombre Ãºnico (e.g., 'read_file')
abstract get description(): string;    // DescripciÃ³n para el prompt del LLM
abstract get parameters(): ToolParameter[];  // Params con tipo y descripciÃ³n
abstract get returns(): string;        // DescripciÃ³n del retorno
abstract execute(params, context): Promise<ToolResult>;
```

MÃ©todos heredados:
- `getDefinition()` â€” Ensambla `ToolDefinition` para el system prompt
- `validateParams()` â€” Valida parÃ¡metros requeridos
- `success(data)` / `error(message)` â€” Helpers para respuestas estandarizadas

### ToolRegistry

Almacena y gestiona todos los tools registrados:

```typescript
class ToolRegistry {
    register(tool: BaseTool): void;
    registerAll(tools: BaseTool[]): void;
    getTool(name: string): BaseTool | undefined;
    execute(name: string, params, context): Promise<ToolResult>;
    getDefinitions(): ToolDefinition[];
    getToolNames(): string[];
    buildToolsPrompt(): string;   // Genera descripciÃ³n de tools para LLM
    parseToolCalls(text): ToolCall[];  // Extrae tool calls del output del LLM
}
```

### Tools Deterministas (sin LLM)

| Tool | Nombre | ParÃ¡metros | FunciÃ³n |
|---|---|---|---|
| `ListSourceFilesTool` | `list_source_files` | `directory` | Busca archivos `.ts/.tsx/.js/.jsx` en el workspace |
| `ReadFileTool` | `read_file` | `filePath` | Lee contenido de un archivo |
| `WriteFileTool` | `write_file` | `filePath`, `content` | Escribe archivo a disco |
| `RunTestTool` | `run_test` | `testFilePath`, `workspaceRoot` | Ejecuta Jest sobre un archivo de test |
| `AnalyzeProjectTool` | `analyze_project` | `workspaceRoot` | Ejecuta `StackDiscoveryService.discover()` |
| `CollectContextTool` | `collect_context` | `sourceFilePath`, `workspaceRoot` | Recopila imports, tipos y contexto de dependencias |

### Tools Inteligentes (usan LLM internamente)

| Tool | Nombre | ParÃ¡metros | FunciÃ³n |
|---|---|---|---|
| `GenerateTestTool` | `generate_test` | `sourceFilePath`, `sourceCode`, `context` | Genera test usando LLM con contexto completo |
| `FixTestTool` | `fix_test` | `testCode`, `errorOutput`, `sourceCode` | Corrige test fallido usando LLM con output de error |

---

## LLMOrchestrator â€” Loop AgÃ©ntico

**Archivo:** `orchestrator/LLMOrchestrator.ts`

### Modo libre: `execute()`

El LLM tiene autonomÃ­a total para elegir quÃ© tools llamar y en quÃ© orden:

```
execute(userRequest, context, stream):
    1. CONSTRUIR system prompt con:
       - Definiciones de todos los tools (nombre, descripciÃ³n, parÃ¡metros)
       - Instrucciones de formato (JSON en code blocks)
       - Regla de terminaciÃ³n ("responde DONE cuando termines")

    2. INICIAR conversation history = [system, user(request)]

    3. LOOP (max 10 iteraciones):
       a. ENVIAR historial completo al LLM
       b. RECIBIR respuesta del LLM (streaming)

       c. SI respuesta contiene "DONE":
            â†’ Extraer resultado final
            â†’ RETORNAR

       d. SI respuesta contiene tool calls (JSON):
            â†’ PARSEAR tool calls [{tool, parameters}]
            â†’ PARA CADA tool call:
                 resultado = toolRegistry.execute(tool, params, context)
                 AGREGAR {role: "tool", result} al historial

       e. SI no hay tool calls ni DONE:
            â†’ AGREGAR respuesta como {role: "assistant"}
            â†’ Continuar loop

    4. SI max iteraciones alcanzadas:
       â†’ RETORNAR Ãºltimo resultado disponible
```

### Modo dirigido: `executeGenerateAndHeal()`

Workflow predefinido para generaciÃ³n + auto-reparaciÃ³n:

```
executeGenerateAndHeal(sourceFilePath, workspaceRoot, stream, token):
    1. COLLECT CONTEXT:
       â†’ CollectContextTool.execute({sourceFilePath, workspaceRoot})
       â†’ Obtener imports, tipos, interfaces del archivo fuente

    2. READ SOURCE:
       â†’ ReadFileTool.execute({filePath: sourceFilePath})

    3. GENERATE TEST:
       â†’ GenerateTestTool.execute({sourceFilePath, sourceCode, context})

    4. WRITE TEST:
       â†’ WriteFileTool.execute({filePath: testPath, content: testCode})

    5. RUN TEST:
       â†’ RunTestTool.execute({testFilePath: testPath, workspaceRoot})

    6. SI test falla Y intentos < maxHealingAttempts:
       â†’ FixTestTool.execute({testCode, errorOutput, sourceCode})
       â†’ ESCRIBIR test corregido
       â†’ VOLVER al paso 5

    7. RETORNAR ruta del test generado
```

---

## Flujo del Chat Handler Principal

**Archivo:** `ChatHandlers.ts`

```
handleChatRequest(request, context, stream, token):
    1. EXTRAER targetPath:
       - Desde referencias adjuntas (#file) en el request
       - O desde el texto del prompt (si contiene ruta)

    2. ENRUTAR por request.command:
       CASO 'setup':
           â†’ handleSetupRequest(stream, token)
       CASO 'install':
           â†’ handleInstallRequest(stream, token, installCommand?)
       CASO 'generate-all':
           â†’ handleGenerateAllRequest(stream, token, stateService, targetPath, orchestrator)
       CASO default (sin comando / 'generate'):
           â†’ handleGenerateSingleRequest(stream, token, stateService, orchestrator)

    3. CATCH errores:
       â†’ handleError(error, stream)
```

---

## Comando /setup

**Handler:** `handleSetupRequest(stream, token)`

```
1. VERIFICAR workspace abierto

2. BUSCAR proyectos con package.json en todos los workspace folders

3. SI no hay proyectos:
   â†’ Mostrar error + sugerencia "File > Open Folder"

4. SI mÃºltiples proyectos:
   â†’ Listar proyectos encontrados con estado Jest

5. SELECCIONAR proyecto (primero por defecto)

6. VERIFICAR estado de Jest (ProjectSetupService.checkProjectSetup):
   â†’ Â¿Tiene jest instalado?
   â†’ Â¿Tiene jest.config?
   â†’ Â¿Tiene scripts de test?

7. SI Jest ya configurado:
   â†’ Mostrar estado actual
   â†’ Sugerir mejoras si procede

8. SI faltan componentes:
   â†’ ProjectSetupService.setupProject(workspaceRoot):
     a. Instalar dependencias (LLM detecta cuÃ¡les)
     b. Generar jest.config.js (LLM personaliza segÃºn proyecto)
     c. Actualizar package.json scripts
     d. Crear mocks necesarios

9. EJECUTAR smoke test (environment-agnostic):
   â†’ expect(1+1).toBe(2)
   â†’ SI proyecto usa jsdom: verificar tambiÃ©n entorno jsdom

10. MOSTRAR resumen al usuario
```

---

## Comando /install

**Handler:** `handleInstallRequest(stream, token, installCommand?, maxRetries=3)`

Incluye un **loop de auto-reparaciÃ³n** donde el LLM diagnostica errores de instalaciÃ³n:

```
1. VERIFICAR workspace

2. VERIFICAR estado de Jest

3. SI no hay comando explÃ­cito:
   â†’ Detectar dependencias faltantes via DependencyDetectionService
   â†’ Construir comando npm install

4. EJECUTAR comando de instalaciÃ³n (spawn npm)

5. SI instalaciÃ³n falla:
   â†’ CAPTURAR error output completo

   LOOP de auto-healing (max 3 intentos):
     a. LLM analiza error npm (analyzeAndFixError)
     b. LLM sugiere comando alternativo
     c. Mostrar diagnÃ³stico al usuario
     d. Ofrecer botÃ³n para reintentar con comando sugerido
     e. SI usuario acepta â†’ ejecutar nuevo comando
     f. SI falla de nuevo â†’ repetir anÃ¡lisis

6. SI todas las tentativas fallan:
   â†’ Mostrar error detallado con sugerencias manuales

7. EJECUTAR smoke test para validar
```

---

## Comando /generate

**Handler:** `handleGenerateSingleRequest(stream, token, stateService, orchestrator?)`

```
1. VERIFICAR editor activo:
   â†’ SI no hay archivo abierto: mostrar instrucciones de uso

2. VALIDAR archivo:
   â†’ ExtensiÃ³n soportada (.ts, .tsx, .js, .jsx)
   â†’ No es un archivo de test (.test., .spec.)

3. OBTENER workspace root

4. VERIFICAR entorno Jest (ensureJestEnvironment):
   â†’ SI Jest no estÃ¡ configurado: ejecutar flow de /setup

5. MOSTRAR encabezado: "Generando Tests para {fileName}"

6. SI orchestrator disponible:
   â†’ orchestrator.executeGenerateAndHeal(sourceFilePath, workspaceRoot, stream, token)
   â†’ El orchestrator maneja todo el ciclo: contexto â†’ generar â†’ escribir â†’ ejecutar â†’ reparar

7. SI NO hay orchestrator (fallback):
   â†’ Crear TestAgent con LLMProviderFactory
   â†’ TestAgent.generateAndHealTest(sourceFilePath, workspaceRoot, stream, token)
   â†’ TestAgent maneja el ciclo clÃ¡sico

8. MOSTRAR resultado:
   â†’ âœ… Test generado exitosamente con ruta del archivo
   â†’ O âš ï¸ Test generado pero con fallos despuÃ©s de N intentos

9. REGISTRAR telemetrÃ­a y abrir archivo de test en editor
```

---

## Comando /generate-all

**Handler:** `handleGenerateAllRequest(stream, token, stateService, targetPath?, orchestrator?)`

```
1. VERIFICAR workspace

2. ESCANEAR archivos fuente:
   â†’ FileScanner.findSourceFiles() para cada workspace folder
   â†’ .ts, .tsx, .js, .jsx (excluyendo node_modules, dist, etc.)

3. FILTRAR archivos sin tests:
   â†’ FileScanner.filterFilesWithoutTests()

4. SI todos tienen tests:
   â†’ Mostrar "âœ… Â¡Todos los archivos ya tienen tests!"

5. AGRUPAR por proyecto:
   â†’ FileScanner.groupFilesByProject()

6. VERIFICAR entorno Jest del primer proyecto

7. ğŸ§  PLANIFICACIÃ“N LLM (planBatchGeneration):
   â†’ LLM analiza lista de archivos, estructura del proyecto, tipos de archivo
   â†’ LLM retorna BatchGenerationPlan:
     - Grupos priorizados (servicios core â†’ componentes â†’ utilidades)
     - RazÃ³n de cada grupo
     - Tiempo estimado
     - Concurrencia recomendada
   â†’ Mostrar plan al usuario (top 3 grupos)

8. REORDENAR archivos segÃºn plan del LLM

9. PROCESAR archivos secuencialmente:
   PARA CADA archivo:
     a. Verificar cancelaciÃ³n (token)
     b. Mostrar progreso (N/total)
     c. SI orchestrator disponible:
          â†’ orchestrator.executeGenerateAndHeal(file, root, stream, token)
        SI NO:
          â†’ TestAgent.generateAndHealTest(file, root, stream, token)
     d. Rate limit: esperar entre archivos
     e. Registrar Ã©xito/fallo

10. MOSTRAR resumen batch:
    â†’ âœ… N tests generados exitosamente
    â†’ âš ï¸ N tests con fallos
    â†’ Tiempo total
```

---

## DetecciÃ³n Inteligente de Dependencias (3 capas)

**Servicio:** `DependencyDetectionService`

El sistema de detecciÃ³n de dependencias usa 3 capas de inteligencia:

```
getCompatibleDependencies(projectRoot):
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Capa 1: StackDiscoveryService           â”‚
    â”‚ (determinista)                          â”‚
    â”‚                                         â”‚
    â”‚ â†’ Lee package.json, tsconfig.json       â”‚
    â”‚ â†’ Detecta: framework, uiLibrary,        â”‚
    â”‚   testRunner, packageManager,            â”‚
    â”‚   moduleSystem, reactVersion, etc.       â”‚
    â”‚ â†’ Resultado: ProjectStack               â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Capa 2: LLM con contexto enriquecido   â”‚
    â”‚                                         â”‚
    â”‚ â†’ Se inyecta _stackAnalysis en el       â”‚
    â”‚   packageJson enviado al LLM            â”‚
    â”‚ â†’ LLM recibe framework detectado,       â”‚
    â”‚   UI library, etc. como contexto        â”‚
    â”‚ â†’ LLM sugiere dependencias compatibles  â”‚
    â”‚ â†’ 3 reintentos con feedback si falla    â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Capa 3: filterByStack() (guardrail)     â”‚
    â”‚ (determinista)                          â”‚
    â”‚                                         â”‚
    â”‚ â†’ Filtro post-LLM que elimina:          â”‚
    â”‚   - Paquetes React si no hay React      â”‚
    â”‚   - Paquetes browser si no hay DOM      â”‚
    â”‚   - Paquetes de framework incorrecto    â”‚
    â”‚ â†’ Asegura que solo se instalan          â”‚
    â”‚   paquetes relevantes al stack real     â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

    Fallback final: solo jest, @types/jest, ts-jest
```

### StackDiscoveryService

Detecta de forma determinista:

| Campo | Valores posibles |
|---|---|
| `framework` | `spfx`, `react`, `angular`, `vue`, `node`, `vscode-extension`, `next`, `express`, `unknown` |
| `language` | `typescript`, `javascript` |
| `uiLibrary` | `react`, `angular`, `vue`, `svelte`, `none` |
| `componentLibrary` | `@fluentui/react`, `@mui/material`, `antd`, `none`, etc. |
| `testRunner` | `jest`, `vitest`, `mocha`, `jasmine`, `none` |
| `packageManager` | `npm`, `yarn`, `pnpm` |
| `moduleSystem` | `commonjs`, `esm`, `mixed` |

Infiere todo desde: `package.json`, archivos de configuraciÃ³n, lockfiles, y estructura de directorios.

---

## Servicios Auxiliares

### Logger
Singleton con niveles configurables (debug, info, warn, error). Output channel: "Test Agent".

### ConfigService
Lee la configuraciÃ³n de VS Code (`test-agent.*`). Emite eventos `onDidChangeConfiguration`.

### StateService
Persiste estado entre sesiones usando `vscode.ExtensionContext.globalState`.

### TelemetryService
TelemetrÃ­a anÃ³nima opcional. Registra ejecuciones de comandos, tiempos, Ã©xitos/fallos.

### CacheService
Cache de respuestas LLM. Reduce llamadas repetidas para el mismo input.

### QueueService
Gestiona cola de generaciÃ³n batch. Controla concurrencia y rate limiting.

### CoverageService
Parsea reportes de cobertura de Jest. Usado para iterar sobre archivos con baja cobertura.

### DependencyGraphService
Construye grafos de importaciÃ³n/dependencia. Usado para priorizaciÃ³n batch.

### PackageInstallationService
Ejecuta comandos `npm install` / `yarn add` / `pnpm add` con captura de output.

### JestConfigurationService
Genera `jest.config.js` personalizado. Usa LLM para adaptar configuraciÃ³n al proyecto.

### ProjectSetupService
Orquesta el flow completo de `/setup`: instalaciÃ³n + configuraciÃ³n + smoke test.

---

## Llamadas Reales al LLM

Todas las interacciones con el LLM son llamadas reales a travÃ©s de la API `vscode.lm`:

### VÃ­a LLMOrchestrator (tool calling)
| OperaciÃ³n | DescripciÃ³n |
|---|---|
| System prompt + user request | El orchestrator envÃ­a definiciones de tools + request al LLM |
| Tool result feedback | DespuÃ©s de ejecutar un tool, el resultado se devuelve al LLM |
| IteraciÃ³n hasta DONE | El LLM decide autÃ³nomamente cuÃ¡ndo ha terminado |

### VÃ­a ILLMProvider (mÃ©todos directos)
| MÃ©todo | Llamada LLM | PropÃ³sito |
|---|---|---|
| `generateTest()` | âœ… Real | Generar cÃ³digo de test |
| `fixTest()` | âœ… Real | Corregir test con error context |
| `planTestStrategy()` | âœ… Real | Planificar enfoque de testing |
| `generateJestConfig()` | âœ… Real | Generar configuraciÃ³n Jest personalizada |
| `detectDependencies()` | âœ… Real | Detectar versiones de dependencias compatibles |
| `planBatchGeneration()` | âœ… Real | Priorizar archivos para generaciÃ³n batch |
| `validateAndFixVersions()` | âœ… Real | Corregir versiones npm invÃ¡lidas |
| `analyzeAndFixError()` | âœ… Real | Diagnosticar errores de instalaciÃ³n npm |
| `sendPrompt()` | âœ… Real | Prompt genÃ©rico (interfaz ICoreProvider) |

### Formato de Respuesta
El LLM responde con tool calls embebidos en bloques de cÃ³digo JSON:

````markdown
Voy a analizar el proyecto primero.

```json
{"tool": "analyze_project", "parameters": {"workspaceRoot": "/path/to/project"}}
```
````

El `ToolRegistry.parseToolCalls()` extrae estos JSON del output del LLM.

---

## Resumen de Componentes

| Componente | Archivo | Responsabilidad |
|---|---|---|
| Entry Point | `extension.ts` | ActivaciÃ³n, registro, inicializaciÃ³n de orchestrator |
| Chat Router | `ChatHandlers.ts` | Enrutamiento de comandos a handlers |
| Orchestrator | `orchestrator/LLMOrchestrator.ts` | Loop agÃ©ntico con tool calling |
| Factory | `orchestrator/OrchestratorFactory.ts` | CreaciÃ³n de ToolRegistry con 8 tools |
| Base Tool | `tools/BaseTool.ts` | Clase abstracta para todos los tools |
| Registry | `tools/ToolRegistry.ts` | Almacenamiento y ejecuciÃ³n de tools |
| Types | `tools/ToolTypes.ts` | Tipos core del sistema de tools |
| Deterministic | `tools/deterministic/*.ts` | 6 tools sin LLM |
| Intelligent | `tools/intelligent/*.ts` | 2 tools con LLM |
| Copilot | `providers/CopilotProvider.ts` | Proveedor via `vscode.lm` API |
| Azure OpenAI | `providers/AzureOpenAIProvider.ts` | Proveedor via `@azure/openai` SDK |
| Test Agent | `agent/TestAgent.ts` | Agente clÃ¡sico de generaciÃ³n (fallback) |
| Code Agent | `agent/CodeAssistantAgent.ts` | Orquestador genÃ©rico de capabilities |
| Stack | `services/StackDiscoveryService.ts` | DetecciÃ³n determinista del stack del proyecto |
| Dependencies | `services/DependencyDetectionService.ts` | DetecciÃ³n LLM-first con 3 capas |
