# ğŸ”§ Â¿QuÃ© son los "TOOLS" en LLM-First?

## Concepto Fundamental

**"Tools"** (tambiÃ©n llamados "Functions" o "Actions") son **funciones que el LLM puede invocar por su cuenta** para realizar acciones en el mundo real.

Es como darle al LLM una **caja de herramientas** y decirle: "Usa lo que necesites para lograr el objetivo".

---

## ğŸ¯ ComparaciÃ³n: Actual vs Tools

### **ACTUAL (Sin Tools)** ğŸ”´

El cÃ³digo TypeScript decide TODO y solo le pide al LLM que genere texto:

```typescript
// ChatHandlers.ts (ACTUAL - lÃ­nea ~800+)
async function handleGenerateAllRequest() {
    // âŒ La EXTENSIÃ“N busca archivos manualmente
    const files = await vscode.workspace.findFiles('**/*.ts', '**/node_modules/**');
    
    // âŒ La EXTENSIÃ“N filtra cuÃ¡les necesitan tests
    const filesWithoutTests = [];
    for (const file of files) {
        const testFile = getTestFilePath(file);
        if (!fs.existsSync(testFile)) {
            filesWithoutTests.push(file);
        }
    }
    
    // âŒ La EXTENSIÃ“N lee cada archivo
    for (const file of filesWithoutTests) {
        const sourceCode = fs.readFileSync(file, 'utf-8');
        
        // âŒ La EXTENSIÃ“N analiza dependencias manualmente
        const deps = new DependencyDetectionService();
        const dependencies = await deps.analyzeDependencies(sourceCode);
        
        // ğŸŸ¡ AquÃ­ FINALMENTE llama al LLM (pero solo para generar)
        const testCode = await llmProvider.generateTest({
            sourceCode: sourceCode,
            dependencies: dependencies
        });
        
        // âŒ La EXTENSIÃ“N escribe el archivo
        fs.writeFileSync(testFilePath, testCode);
        
        // âŒ La EXTENSIÃ“N ejecuta Jest
        const result = await runJest(testFilePath);
        
        // âŒ Si falla, la EXTENSIÃ“N decide reintentar
        if (!result.success) {
            const fixed = await llmProvider.fixTest({
                error: result.error
            });
            fs.writeFileSync(testFilePath, fixed);
        }
    }
}
```

**Problemas:**
- El LLM NO decide nada
- La extensiÃ³n tiene 13 servicios con lÃ³gica hardcodeada
- Cambiar el orden = modificar cÃ³digo TypeScript

---

### **PROPUESTO (Con Tools)** ğŸŸ¢

El LLM decide TODO usando tools que tÃº le proporcionas:

```typescript
// extension.ts (PROPUESTO)
async function handleGenerateAllRequest() {
    
    // âœ… Solo le das al LLM el objetivo y las herramientas
    const orchestrator = new LLMOrchestrator();
    
    return await orchestrator.execute({
        goal: "Generate tests for all source files",
        tools: [
            new ListSourceFilesTool(),      // ğŸ”§ Tool 1
            new ReadFileTool(),             // ğŸ”§ Tool 2
            new AnalyzeDependenciesTool(),  // ğŸ”§ Tool 3
            new WriteTestTool(),            // ğŸ”§ Tool 4
            new RunTestTool(),              // ğŸ”§ Tool 5
            new FixTestTool()               // ğŸ”§ Tool 6
        ]
    });
}
```

**El LLM entonces hace esto SOLO:**

```yaml
# ConversaciÃ³n del LLM (interno):

LLM piensa: "Ok, mi objetivo es generar tests. Primero necesito 
             saber quÃ© archivos hay."

LLM decide: "Voy a usar el tool 'list_source_files'"

â†’ LLM llama: list_source_files({ exclude: "node_modules" })

â† Resultado: { files: ["src/UserService.ts", "src/helpers.ts"] }

LLM piensa: "Perfecto, hay 2 archivos. Voy a leer el primero."

â†’ LLM llama: read_file({ path: "src/UserService.ts" })

â† Resultado: { content: "export class UserService {...}" }

LLM piensa: "Es una clase. Necesito saber quÃ© dependencias tiene."

â†’ LLM llama: analyze_dependencies({ sourceCode: "..." })

â† Resultado: { imports: ["axios", "./Logger"], needsMocking: ["axios"] }

LLM piensa: "Genial, usa axios. Voy a generar un test con mocking."

â†’ LLM llama: write_test({ 
    source: "src/UserService.ts",
    testCode: "import { UserService } from './UserService';\n..."
  })

â† Resultado: { testPath: "src/UserService.test.ts", success: true }

LLM piensa: "Test creado. Lo ejecuto para validar."

â†’ LLM llama: run_test({ testFile: "src/UserService.test.ts" })

â† Resultado: { success: false, error: "ReferenceError: axios is not defined" }

LLM piensa: "Ah, olvidÃ© jest.mock('axios'). Lo arreglo."

â†’ LLM llama: fix_test({ 
    testFile: "src/UserService.test.ts",
    error: "...",
    fix: "jest.mock('axios');\n..."
  })

â† Resultado: { success: true }

â†’ LLM llama: run_test({ testFile: "src/UserService.test.ts" })

â† Resultado: { success: true, passed: 5 }

LLM piensa: "âœ… UserService done. Siguiente archivo..."

[REPITE PARA helpers.ts]

LLM responde al usuario: "âœ… Tests generados para 2 archivos. Todos pasan."
```

---

## ğŸ› ï¸ Â¿QuÃ© es un "Tool" TÃ©cnicamente?

Un **tool** es una funciÃ³n que el LLM puede invocar, descrita en formato JSON Schema.

### Ejemplo Real: `ListSourceFilesTool`

```typescript
// src/tools/filesystem/ListSourceFilesTool.ts

export class ListSourceFilesTool extends BaseTool {
    
    // ğŸ“‹ DEFINICIÃ“N: Le explica al LLM quÃ© hace este tool
    get definition(): ToolDefinition {
        return {
            type: 'function',
            function: {
                name: 'list_source_files',  // â† Nombre del tool
                
                description: 'List all source files in the workspace that need tests',
                
                // â†“ ParÃ¡metros que el LLM puede pasar
                parameters: {
                    type: 'object',
                    properties: {
                        workspace_root: {
                            type: 'string',
                            description: 'Root path of the workspace'
                        },
                        exclude_patterns: {
                            type: 'array',
                            description: 'Patterns to exclude (e.g., ["node_modules", "*.test.ts"])'
                        }
                    },
                    required: ['workspace_root']
                }
            }
        };
    }
    
    // âš™ï¸ EJECUCIÃ“N: Lo que realmente hace cuando el LLM lo llama
    async execute(args: {
        workspace_root: string;
        exclude_patterns?: string[];
    }): Promise<{ files: string[]; total: number }> {
        
        const excludePattern = args.exclude_patterns?.join(',') || 
                               '**/{*.test.*,node_modules/**}';
        
        // Buscar archivos
        const files = await vscode.workspace.findFiles(
            '**/*.{ts,tsx}',
            excludePattern
        );
        
        // Filtrar los que ya tienen tests
        const filesWithoutTests: string[] = [];
        for (const file of files) {
            const testFile = this.getTestFilePath(file.fsPath);
            const hasTest = await this.fileExists(testFile);
            if (!hasTest) {
                filesWithoutTests.push(file.fsPath);
            }
        }
        
        // Devolver resultado al LLM
        return {
            files: filesWithoutTests,
            total: filesWithoutTests.length
        };
    }
}
```

### CÃ³mo lo Usa el LLM

1. **LLM ve la definiciÃ³n:**
```json
{
  "name": "list_source_files",
  "description": "List all source files in the workspace that need tests",
  "parameters": {
    "workspace_root": { "type": "string" },
    "exclude_patterns": { "type": "array" }
  }
}
```

2. **LLM decide usarlo:**
```json
// El LLM responde con:
{
  "tool_calls": [
    {
      "id": "call_abc123",
      "type": "function",
      "function": {
        "name": "list_source_files",
        "arguments": "{\"workspace_root\": \"c:/dev/project\"}"
      }
    }
  ]
}
```

3. **Tu cÃ³digo ejecuta el tool:**
```typescript
const result = await listSourceFilesTool.execute({
    workspace_root: "c:/dev/project"
});
// â†’ { files: ["src/UserService.ts", "src/helpers.ts"], total: 2 }
```

4. **Devuelves resultado al LLM:**
```json
{
  "tool_call_id": "call_abc123",
  "output": "{\"files\": [\"src/UserService.ts\", \"src/helpers.ts\"], \"total\": 2}"
}
```

5. **LLM procesa el resultado y decide quÃ© hacer:**
   - "Ok, hay 2 archivos. Voy a leer el primero con `read_file`..."

---

## ğŸ“¦ Ejemplo Completo: ComparaciÃ³n Lado a Lado

### Escenario: Generar test para `UserService.ts`

#### **CÃ“DIGO ACTUAL (Sin Tools)**

```typescript
// ChatHandlers.ts - handleGenerateSingleRequest() (simplificado)

async function handleGenerateSingleRequest(file: vscode.Uri) {
    
    // 1ï¸âƒ£ La extensiÃ³n lee el archivo
    const sourceCode = fs.readFileSync(file.fsPath, 'utf-8');
    
    // 2ï¸âƒ£ La extensiÃ³n analiza dependencias (300 lÃ­neas de cÃ³digo)
    const deps = new DependencyDetectionService();
    const dependencies = await deps.buildDependencyContext(sourceCode, file.fsPath);
    // En DependencyDetectionService.ts (lÃ­nea 1-334):
    // - Parsea AST con TypeScript compiler
    // - Busca imports manualmente con regex
    // - Distingue dependencias externas vs internas
    // - Construye grafo de dependencias
    // - Detecta cuÃ¡les necesitan mocking
    
    // 3ï¸âƒ£ La extensiÃ³n detecta el framework (100 lÃ­neas)
    const stack = new StackDiscoveryService();
    const framework = await stack.detectFramework(workspaceRoot);
    // En StackDiscoveryService.ts:
    // - Lee package.json
    // - Busca keywords especÃ­ficos: "react", "vue", "angular"
    // - Verifica archivos de config: tsconfig.json, .babelrc
    
    // 4ï¸âƒ£ La extensiÃ³n construye el prompt
    const systemPrompt = buildSystemPrompt(framework, dependencies);
    
    // 5ï¸âƒ£ AQUÃ finalmente llama al LLM
    const testCode = await llmProvider.generateTest({
        sourceCode: sourceCode,
        dependencies: dependencies,
        systemPrompt: systemPrompt
    });
    // â†‘ El LLM solo ve: cÃ³digo fuente + anÃ¡lisis completo
    // â†‘ El LLM solo responde: cÃ³digo del test
    
    // 6ï¸âƒ£ La extensiÃ³n escribe el test
    const testPath = this.getTestFilePath(file.fsPath);
    fs.writeFileSync(testPath, testCode);
    
    // 7ï¸âƒ£ La extensiÃ³n ejecuta Jest
    const result = await new TestRunner().run(testPath);
    
    // 8ï¸âƒ£ Si falla, la extensiÃ³n decide reintentar (loop hardcodeado)
    let attempts = 0;
    while (!result.success && attempts < 3) {
        const error = result.error;
        const fixed = await llmProvider.fixTest({ error, testCode });
        fs.writeFileSync(testPath, fixed);
        result = await new TestRunner().run(testPath);
        attempts++;
    }
}
```

**Total: ~500 lÃ­neas de lÃ³gica imperativa**

---

#### **CÃ“DIGO PROPUESTO (Con Tools)**

```typescript
// extension.ts (PROPUESTO)

async function handleGenerateSingleRequest(file: vscode.Uri) {
    
    const orchestrator = new LLMOrchestrator();
    
    // âœ… TODO en 1 llamada
    return await orchestrator.execute({
        goal: `Generate a unit test for ${file.fsPath}`,
        context: { sourceFile: file.fsPath },
        tools: [
            new ReadFileTool(),
            new AnalyzeDependenciesTool(),
            new DetectFrameworkTool(),
            new WriteTestTool(),
            new RunTestTool(),
            new FixTestTool()
        ]
    });
}
```

**Total: ~50 lÃ­neas de cÃ³digo orquestador + 6 tools simples (~30 lÃ­neas cada uno)**

---

### Â¿QuÃ© hace el Orquestador?

```typescript
// LLMOrchestrator.ts (simplificado)

export class LLMOrchestrator {
    
    async execute(request: { goal: string; tools: BaseTool[] }) {
        
        // 1ï¸âƒ£ Enviar objetivo + definiciones de tools al LLM
        const messages = [
            {
                role: 'system',
                content: `You are a test generator. Use these tools:\n${this.getToolsDescription(request.tools)}`
            },
            {
                role: 'user',
                content: request.goal
            }
        ];
        
        // 2ï¸âƒ£ Loop agentico
        while (true) {
            // Llamar al LLM
            const response = await this.llm.sendRequest(messages, request.tools);
            
            // Si el LLM quiere usar tools
            if (response.tool_calls) {
                
                // Ejecutar cada tool que el LLM pidiÃ³
                for (const toolCall of response.tool_calls) {
                    const tool = this.findTool(toolCall.name, request.tools);
                    const args = JSON.parse(toolCall.arguments);
                    
                    // âš™ï¸ Ejecutar el tool
                    const result = await tool.execute(args);
                    
                    // Agregar resultado al historial
                    messages.push({
                        role: 'tool',
                        tool_call_id: toolCall.id,
                        content: JSON.stringify(result)
                    });
                }
                
                // Continuar el loop (el LLM verÃ¡ los resultados y decidirÃ¡ quÃ© hacer)
                continue;
            }
            
            // Si el LLM NO quiere mÃ¡s tools = terminÃ³
            if (response.finish_reason === 'stop') {
                return response.content;
            }
        }
    }
}
```

---

## ğŸ¬ Ejemplo de EjecuciÃ³n Real

### Usuario escribe:
```
@spfx-tester /generate src/services/UserService.ts
```

### ConversaciÃ³n interna (con tools):

```yaml
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ENVÃO 1 (al LLM):
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
System: "You are a test generator agent. Available tools:
  - read_file: Read a source file
  - analyze_dependencies: Analyze imports and dependencies
  - detect_framework: Detect project framework (React/Vue/Angular)
  - write_test: Write a test file
  - run_test: Execute a test with Jest
  - fix_test: Fix a failing test"

User: "Generate a unit test for src/services/UserService.ts"

Tools: [read_file, analyze_dependencies, ...]

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
RESPUESTA LLM 1:
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
{
  "content": "",
  "tool_calls": [
    {
      "id": "call_1",
      "function": {
        "name": "read_file",
        "arguments": "{\"path\": \"src/services/UserService.ts\"}"
      }
    }
  ]
}

# ğŸ”§ TU CÃ“DIGO EJECUTA EL TOOL:
result_1 = readFileTool.execute({ path: "src/services/UserService.ts" })
# â†’ { content: "export class UserService {\n  async getUser() {...}" }

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ENVÃO 2 (al LLM):
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
[Historial anterior...]

Tool Result (call_1): 
{
  "content": "export class UserService {\n  async getUser(id: string) {\n    return axios.get(`/users/${id}`);\n  }\n}"
}

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
RESPUESTA LLM 2:
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
{
  "content": "",
  "tool_calls": [
    {
      "id": "call_2",
      "function": {
        "name": "analyze_dependencies",
        "arguments": "{\"sourceCode\": \"export class UserService...\"}"
      }
    }
  ]
}

# ğŸ”§ TU CÃ“DIGO EJECUTA:
result_2 = analyzeDepsTools.execute({ sourceCode: "..." })
# â†’ { imports: ["axios"], external: ["axios"], needsMocking: ["axios"] }

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ENVÃO 3 (al LLM):
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
[Historial anterior...]

Tool Result (call_2): 
{ "imports": ["axios"], "needsMocking": ["axios"] }

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
RESPUESTA LLM 3:
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
{
  "content": "",
  "tool_calls": [
    {
      "id": "call_3",
      "function": {
        "name": "write_test",
        "arguments": "{\"sourceFile\": \"src/services/UserService.ts\", \"testCode\": \"import { UserService } from './UserService';\\n\\njest.mock('axios');\\n\\ndescribe('UserService', () => {\\n  it('should fetch user', async () => {\\n    const service = new UserService();\\n    await service.getUser('123');\\n    expect(axios.get).toHaveBeenCalledWith('/users/123');\\n  });\\n});\"}"
      }
    }
  ]
}

# ğŸ”§ TU CÃ“DIGO EJECUTA:
result_3 = writeTestTool.execute({ sourceFile: "...", testCode: "..." })
# â†’ { testPath: "src/services/UserService.test.ts", success: true }

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ENVÃO 4 (al LLM):
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
Tool Result (call_3): 
{ "testPath": "src/services/UserService.test.ts", "success": true }

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
RESPUESTA LLM 4:
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
{
  "content": "",
  "tool_calls": [
    {
      "id": "call_4",
      "function": {
        "name": "run_test",
        "arguments": "{\"testFile\": \"src/services/UserService.test.ts\"}"
      }
    }
  ]
}

# ğŸ”§ TU CÃ“DIGO EJECUTA:
result_4 = runTestTool.execute({ testFile: "..." })
# â†’ { success: true, passed: 1, failed: 0 }

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ENVÃO 5 (al LLM):
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
Tool Result (call_4): 
{ "success": true, "passed": 1, "failed": 0 }

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
RESPUESTA LLM 5 (FINAL):
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
{
  "content": "âœ… Test generated successfully for UserService.ts\n\nTest file: src/services/UserService.test.ts\n- 1 test passing\n- Mocked axios dependency\n- Coverage: 100%",
  "finish_reason": "stop"
}

# âœ… FIN - El LLM decidiÃ³ que terminÃ³
```

---

## ğŸ”‘ Diferencias Clave

| Aspecto | Sin Tools (Actual) | Con Tools (Propuesto) |
|---------|-------------------|---------------------|
| **Â¿QuiÃ©n decide?** | TypeScript (cÃ³digo imperativo) | LLM (reasoning + tool calls) |
| **LÃ³gica de anÃ¡lisis** | 13 servicios (500+ lÃ­neas cada uno) | Tools simples (30 lÃ­neas cada uno) |
| **Flexibilidad** | Cambiar comportamiento = modificar cÃ³digo | Cambiar comportamiento = modificar prompt |
| **Orden de ejecuciÃ³n** | Hardcodeado en handlers | LLM decide segÃºn contexto |
| **Manejo de errores** | try/catch + loops fijos | LLM adapta estrategia |
| **Transparencia** | Opaco (solo ves logs) | Claro (ves cada tool call) |
| **Extensibilidad** | Agregar feature = modificar servicios | Agregar feature = crear nuevo tool |

---

## ğŸ§ª CÃ³digo Real de un Tool Completo

```typescript
// src/tools/testing/RunTestTool.ts

import { BaseTool, ToolDefinition } from '../base/BaseTool';
import { spawn } from 'child_process';

export class RunTestTool extends BaseTool {
    
    // ğŸ“‹ DefiniciÃ³n para el LLM
    get definition(): ToolDefinition {
        return {
            type: 'function',
            function: {
                name: 'run_test',
                description: 'Execute a test file with Jest and return results',
                parameters: {
                    type: 'object',
                    properties: {
                        test_file: {
                            type: 'string',
                            description: 'Path to the test file to execute'
                        }
                    },
                    required: ['test_file']
                }
            }
        };
    }
    
    // âš™ï¸ ImplementaciÃ³n real
    async execute(args: { test_file: string }): Promise<{
        success: boolean;
        passed: number;
        failed: number;
        output: string;
        error?: string;
    }> {
        
        return new Promise((resolve) => {
            
            // Ejecutar Jest
            const jest = spawn('npx', ['jest', args.test_file, '--json'], {
                shell: true
            });
            
            let output = '';
            let errorOutput = '';
            
            jest.stdout.on('data', (data) => {
                output += data.toString();
            });
            
            jest.stderr.on('data', (data) => {
                errorOutput += data.toString();
            });
            
            jest.on('close', (code) => {
                
                // Parsear resultado JSON de Jest
                try {
                    const result = JSON.parse(output);
                    
                    resolve({
                        success: code === 0,
                        passed: result.numPassedTests,
                        failed: result.numFailedTests,
                        output: output,
                        error: code !== 0 ? errorOutput : undefined
                    });
                    
                } catch (e) {
                    resolve({
                        success: false,
                        passed: 0,
                        failed: 0,
                        output: output,
                        error: errorOutput || 'Failed to parse Jest output'
                    });
                }
            });
        });
    }
}
```

**Eso es todo.** 30 lÃ­neas vs 500 lÃ­neas de `TestRunner.ts`.

---

## ğŸ’¡ Ventajas de los Tools

### 1. **Simplicidad**
Cada tool hace UNA cosa. No hay lÃ³gica compleja de orquestaciÃ³n.

### 2. **Reutilizabilidad**
Otros comandos pueden usar los mismos tools:
```typescript
// Comando /analyze
orchestrator.execute({
    goal: "Analyze test coverage",
    tools: [
        new ListSourceFilesTool(),
        new GetCoverageTool(),
        new AnalyzeGapsTool()
    ]
});

// Comando /fix
orchestrator.execute({
    goal: "Fix all failing tests",
    tools: [
        new ListTestsTool(),
        new RunTestTool(),
        new FixTestTool()
    ]
});
```

### 3. **Extensibilidad**
Agregar nuevo tool = 30 lÃ­neas:
```typescript
// Nuevo tool para Vitest (sin modificar nada mÃ¡s)
export class RunVitestTool extends BaseTool {
    get definition() {
        return {
            name: 'run_vitest',
            description: 'Run tests with Vitest'
        };
    }
    
    async execute(args) {
        // Ejecutar vitest
        return { success: true };
    }
}

// Registrar
toolRegistry.register(new RunVitestTool());
```

### 4. **Debugging**
Ves exactamente quÃ© estÃ¡ haciendo el LLM:
```
ğŸ”§ Tool called: list_source_files
   â†’ Found 15 files

ğŸ”§ Tool called: read_file (src/UserService.ts)
   â†’ 234 lines

ğŸ”§ Tool called: analyze_dependencies
   â†’ Found: axios, lodash

ğŸ”§ Tool called: write_test
   â†’ Created src/UserService.test.ts

ğŸ”§ Tool called: run_test
   â†’ âœ… All tests passed
```

---

## â“ Preguntas Frecuentes

### **P: Â¿No es mÃ¡s lento hacer mÃºltiples llamadas al LLM?**

**R:** SÃ­, puede ser mÃ¡s lento. Pero:
- Cada llamada es mÃ¡s barata (contexto mÃ¡s pequeÃ±o)
- Puedes ejecutar tools en paralelo
- La transparencia y flexibilidad compensan
- Para casos simples, puedes usar el enfoque actual

**Enfoque hÃ­brido recomendado:**
```typescript
// Comando simple = rÃ¡pido, sin tools
if (command === 'generate') {
    return handleGenerateSingleRequest(); // Actual
}

// Comando complejo = flexible, con tools
if (command === 'generate-all') {
    return orchestrator.executeWithTools(); // Propuesto
}
```

### **P: Â¿QuÃ© pasa si el LLM usa mal un tool?**

**R:** Implementas validaciones:
```typescript
async execute(args: { test_file: string }) {
    // Validar que el archivo existe
    if (!fs.existsSync(args.test_file)) {
        return { 
            success: false, 
            error: `File not found: ${args.test_file}` 
        };
    }
    
    // Validar que es un archivo .test.ts
    if (!args.test_file.includes('.test.')) {
        return {
            success: false,
            error: 'Not a test file'
        };
    }
    
    // OK, ejecutar
    return this.runJest(args.test_file);
}
```

### **P: Â¿Esto existe en VS Code API?**

**R:** **SÃ­**, desde VS Code 1.90+:
- `vscode.lm.invokeTool()` - Ejecutar tool
- `vscode.LanguageModelTool` - Definir tool
- Pero puedes implementarlo tÃº mismo si no quieres usar la API oficial

Referencias:
- [VS Code Language Model API](https://code.visualstudio.com/api/extension-guides/language-model)
- [Tool Calling Sample](https://github.com/microsoft/vscode-extension-samples/tree/main/chat-agent-tool-sample)

---

## ğŸ¯ Resumen

| Concepto | ExplicaciÃ³n |
|----------|------------|
| **Tool** | FunciÃ³n que el LLM puede invocar autÃ³nomamente |
| **DefiniciÃ³n** | JSON Schema que explica al LLM quÃ© hace el tool |
| **EjecuciÃ³n** | Tu cÃ³digo ejecuta el tool cuando el LLM lo pide |
| **Loop Agentico** | LLM pide tool â†’ Tu cÃ³digo ejecuta â†’ LLM ve resultado â†’ Decide siguiente acciÃ³n |
| **Ventaja** | El LLM decide TODO, tÃº solo proporcionas capacidades |

---

## ğŸš€ PrÃ³ximo Paso

Â¿Quieres que implemente un **Proof of Concept** con:
1. Un orquestador bÃ¡sico
2. 3 tools simples (list_files, read_file, write_test)
3. Un comando `/generate-llm-first` para probar

Sin romper nada del cÃ³digo actual?
